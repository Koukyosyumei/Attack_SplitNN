{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "direct-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from utils.utils import DataSet\n",
    "from splitnn.model import Client, Server, SplitNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "familiar-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "utility-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\":128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continent-wrapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "architectural-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pharmaceutical-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_neg = raw_df[raw_df[\"Class\"] == 0]\n",
    "raw_df_pos = raw_df[raw_df[\"Class\"] == 1]\n",
    "\n",
    "down_df_neg = raw_df_neg#.sample(40000)\n",
    "down_df = pd.concat([down_df_neg, raw_df_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regional-seminar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 284807\n",
      "    Positive: 492 (0.17% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(down_df['Class'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "settled-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = down_df.copy()\n",
    "\n",
    "# You don't want the `Time` column.\n",
    "cleaned_df.pop('Time')\n",
    "\n",
    "# The `Amount` column covers a huge range. Convert to log-space.\n",
    "eps = 0.001 # 0 => 0.1¢\n",
    "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "destroyed-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "durable-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (182276,)\n",
      "Validation labels shape: (45569,)\n",
      "Test labels shape: (56962,)\n",
      "Training features shape: (182276, 29)\n",
      "Validation features shape: (45569, 29)\n",
      "Test features shape: (56962, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "african-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_features,\n",
    "                        train_labels.astype(np.float64).reshape(-1, 1))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=config[\"batch_size\"],\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = DataSet(test_features,\n",
    "                       test_labels.astype(np.float64).reshape(-1, 1))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=config[\"batch_size\"],\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "behavioral-structure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SecondNet(\n",
       "  (L2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 16\n",
    "\n",
    "class FirstNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FirstNet, self).__init__()        \n",
    "        self.L1 = nn.Linear(train_features.shape[-1],\n",
    "                            hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SecondNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SecondNet, self).__init__()        \n",
    "        self.L2 = nn.Linear(hidden_dim,\n",
    "                            1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model_1 = FirstNet()\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "model_2 = SecondNet()\n",
    "model_2 = model_2.to(device)\n",
    "\n",
    "model_1.double()\n",
    "model_2.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "logical-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "opt_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "opt_2 = optim.Adam(model_2.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "changed-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(model_1, opt_1)\n",
    "server = Server(model_2, opt_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "general-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_auc(label, pred):\n",
    "    return roc_auc_score(label.detach().numpy(),\n",
    "                         pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "violent-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = SplitNN(client, server, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fossil-bearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.00057904, metric 0.8411499868114477\n",
      "epoch 2, loss 3.6767e-05, metric 0.9357675554285548\n",
      "epoch 3, loss 2.9641e-05, metric 0.9621937141894169\n",
      "epoch 4, loss 2.7405e-05, metric 0.9704612238243869\n",
      "epoch 5, loss 2.6088e-05, metric 0.9760471802142408\n",
      "epoch 6, loss 2.473e-05, metric 0.9790083857211939\n",
      "epoch 7, loss 2.319e-05, metric 0.9822661046877977\n",
      "epoch 8, loss 2.1743e-05, metric 0.9862272680646533\n",
      "epoch 9, loss 1.9893e-05, metric 0.9882808080919095\n",
      "epoch 10, loss 1.8333e-05, metric 0.9892892835685291\n"
     ]
    }
   ],
   "source": [
    "sn.fit(train_loader, 10, metric=torch_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server_max_norm(Server):\n",
    "    def __init__(self, server_model,\n",
    "                server_optimizer,\n",
    "                criterion):\n",
    "        super().__init__(server_model,\n",
    "                server_optimizer,\n",
    "                criterion)\n",
    "        \n",
    "    def max_norm(self, grad):\n",
    "        \"\"\"server-side heuristic approach to prevent label leakage attacks\n",
    "           https://arxiv.org/abs/2102.08504\n",
    "\n",
    "        Args:\n",
    "            grad (torch.Tensor): the gradient of L with respect to the\n",
    "                                 input of the function h\n",
    "\n",
    "                                 ---\n",
    "                                 L : the loss function\n",
    "                                 f : the client side model\n",
    "                                 h : the server side model\n",
    "                                 the whole model can be expressed as h ◦ f\n",
    "\n",
    "\n",
    "        Returns\n",
    "            pertubated_gard (torch.Tensor): noised gradient which is\n",
    "                                            supposed to be sent to the client\n",
    "        \"\"\"\n",
    "\n",
    "        g_norm = grad.pow(2).sum(dim=list(range(1, len(grad.shape)))).sqrt()\n",
    "        # maximum gradient norm among the mini-batch\n",
    "        g_max = g_norm[torch.argmax(g_norm)]\n",
    "        # the standard deviation to be determined\n",
    "        sigma = torch.sqrt(g_max / g_norm - 1)\n",
    "        # gausiaan noise\n",
    "        perturbation = torch.normal(torch.zeros_like(sigma), sigma)\n",
    "        # expand dimension\n",
    "        perturbation = perturbation.expand(list(grad.shape)[::-1]).T\n",
    "        # perturbed gradient\n",
    "        pertubated_gard = grad + perturbation\n",
    "\n",
    "        return pertubated_gard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_max_norm(Client):\n",
    "    def __init__(self, client_model,\n",
    "                 client_optimizer):\n",
    "        super().__init__(client_model, client_optimizer)\n",
    "        \n",
    "    def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
