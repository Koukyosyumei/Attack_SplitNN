{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mighty-ready",
   "metadata": {},
   "source": [
    "# Membership Inference Attack (MIA)\n",
    "\n",
    "We demonstate *transfer-inherit shadow learning* which is membership inference attack for collaborative inference like SplitNN.\n",
    "\n",
    "reference  \n",
    "https://ieeexplore.ieee.org/document/9302683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statutory-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacksplitnn.splitnn import Client, Server, SplitNN\n",
    "from attacksplitnn.attack import TransferInherit\n",
    "from attacksplitnn.utils import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "postal-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-wallace",
   "metadata": {},
   "source": [
    "## Set paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "damaged-trade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(42)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-membrane",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "athletic-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(trainset.data)\n",
    "y_train = np.array(trainset.targets)\n",
    "\n",
    "X_test = np.array(testset.data)\n",
    "y_test = np.array(testset.targets)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fatal-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 28, 28) (4000,)\n",
      "(1000, 28, 28) (1000,)\n",
      "(2000, 28, 28) (2000,)\n"
     ]
    }
   ],
   "source": [
    "victim_idx = random.sample(range(X_train.shape[0]), k=4000)\n",
    "attack_idx = random.sample(range(X_test.shape[0]), k=3000)\n",
    "shadow_idx = attack_idx[:1000]\n",
    "eval_idx = attack_idx[1000:]\n",
    "\n",
    "X_victim = X_train[victim_idx]\n",
    "y_victim = y_train[victim_idx]\n",
    "\n",
    "X_shadow = X_test[shadow_idx]\n",
    "y_shadow = y_test[shadow_idx]\n",
    "\n",
    "X_eval = X_test[eval_idx]\n",
    "y_eval = y_test[eval_idx]\n",
    "\n",
    "print(X_victim.shape, y_victim.shape)\n",
    "print(X_shadow.shape, y_shadow.shape)\n",
    "print(X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strange-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "\n",
    "victimset = DataSet(X_victim, y_victim, transform=transform)\n",
    "victimloader = torch.utils.data.DataLoader(victimset, batch_size=64, shuffle=True)\n",
    "\n",
    "shadowset = DataSet(X_shadow, y_shadow, transform=transform)\n",
    "shadowloader = torch.utils.data.DataLoader(shadowset, batch_size=64, shuffle=True)\n",
    "\n",
    "valset = DataSet(X_eval, y_eval, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-space",
   "metadata": {},
   "source": [
    "## Train victim SplitNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metric-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FirstNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64,\n",
    "                               kernel_size=3, padding=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1) \n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3ch > 64ch, shape 32 x 32 > 16 x 16\n",
    "        x = self.conv1(x) # [64,32,32]\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [64,16,16]\n",
    "        \n",
    "        # 64ch > 128ch, shape 16 x 16 > 8 x 8\n",
    "        x = self.conv2(x) # [128,16,16]\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [128,8,8]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "speaking-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNを実装する\n",
    "class SecondNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SecondNet, self).__init__()\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.L1 = nn.Linear(512, 10) # 10クラス分類\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 128ch > 256ch, shape 8 x 8 > 4 x 4\n",
    "        x = self.conv3(x) # [256,8,8]\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [256,4,4]   \n",
    "\n",
    "        # 256ch > 512ch, shape 4 x 4 > 2 x 2\n",
    "        x = self.conv4(x) # [512,4,4]\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2) # [512,2,2]\n",
    "        # 全結合層\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.L1(x)\n",
    "        #x = F.softmax(x, dim=0)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recognized-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = FirstNet()\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "model_2 = SecondNet()\n",
    "model_2 = model_2.to(device)\n",
    "\n",
    "opt_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "opt_2 = optim.Adam(model_2.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(label, output):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    return pred.eq(label.view_as(pred)).sum().item() / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adapted-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(model_1)\n",
    "server = Server(model_2)\n",
    "\n",
    "splitnn = SplitNN(client, server, opt_1, opt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fiscal-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006454377054236828 0.883\n",
      "0.0009821921233087781 0.9835\n",
      "0.0004888799352338537 0.99275\n"
     ]
    }
   ],
   "source": [
    "splitnn.train()\n",
    "for epoch in range(3):\n",
    "    epoch_loss = 0\n",
    "    epoch_outputs = []\n",
    "    epoch_labels = []\n",
    "    for i, data in enumerate(victimloader):\n",
    "        splitnn.zero_grads()\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = splitnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item() / len(victimloader.dataset)\n",
    "        \n",
    "        epoch_outputs.append(outputs)\n",
    "        epoch_labels.append(labels)\n",
    "        \n",
    "        splitnn.backward()\n",
    "        splitnn.step()\n",
    "        \n",
    "    print(epoch_loss, accuracy(torch.cat(epoch_labels),\n",
    "                                torch.cat(epoch_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-blast",
   "metadata": {},
   "source": [
    "## Train shadow model\n",
    "\n",
    "The server wants to execute a membership inference attack against the client, so the server needs the shadow model to mimic the client. The server uses pre-trained alexnet as a shadow model and concatenates it with the server-side model to create the system that imitates the victim SplitNN. Then, the server can create the membership dataset and train the attacker classifier. In this notebook, we use SVM as an attacker model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hollow-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\kanka/.cache\\torch\\hub\\pytorch_vision_v0.9.0\n"
     ]
    }
   ],
   "source": [
    "model_transfer = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)\n",
    "model_1_shadow = model_transfer.features\n",
    "model_1_shadow[0] = nn.Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "model_1_shadow = nn.Sequential(model_1_shadow,\n",
    "                               nn.Conv2d(256, 128, kernel_size=(1, 1),\n",
    "                                         stride=(2, 2), padding=(6, 6)))\n",
    "opt_3 = optim.Adam(model_1_shadow.parameters(), lr=1e-3)\n",
    "\n",
    "shadow_client = Client(model_1_shadow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "buried-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fallen-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "smia = TransferInherit(shadow_client, server, opt_3, attacker_clf, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-basics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training shadow model\n",
      "epoch 1, loss 0.022988, metric 0.556\n",
      "epoch 2, loss 0.0089202, metric 0.853\n",
      "epoch 3, loss 0.0051415, metric 0.915\n",
      "epoch 4, loss 0.0030353, metric 0.955\n",
      "epoch 5, loss 0.0022027, metric 0.97\n",
      "start creating dataset for attacker\n"
     ]
    }
   ],
   "source": [
    "smia.attack(shadowloader, valloader,\n",
    "         5, criterion, shadow_metric=accuracy,\n",
    "         attack_dataset_split=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-carter",
   "metadata": {},
   "source": [
    "## The performance of Membership Inference Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alleged-material",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train AUC 0.7298623286971153\n",
      "test AUC 0.5173987501637981\n"
     ]
    }
   ],
   "source": [
    "pred_proba = smia._predict_proba_attacker_clf(smia.attacker_X_train)[:,0]\n",
    "print(\"train AUC\", roc_auc_score(smia.attacker_y_train, pred_proba))\n",
    "\n",
    "pred_proba = smia._predict_proba_attacker_clf(smia.attacker_X_test)[:,0]\n",
    "print(\"test AUC\", roc_auc_score(smia.attacker_y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
