{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fluid-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.splitnn import Client, Server, SplitNN\n",
    "from src.defense.noised_grad import max_norm\n",
    "from src.measure import label_leak_auc\n",
    "from src.utils.utils import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "played-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import attack_splitnn\n",
    "from attack_splitnn import attack\n",
    "from attack_splitnn import defense\n",
    "from attack_splitnn import measure\n",
    "from attack_splitnn import splitnn\n",
    "from attack_splitnn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-savage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distributed-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_size\":128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appointed-balloon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finnish-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binary-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_neg = raw_df[raw_df[\"Class\"] == 0]\n",
    "raw_df_pos = raw_df[raw_df[\"Class\"] == 1]\n",
    "\n",
    "down_df_neg = raw_df_neg#.sample(40000)\n",
    "down_df = pd.concat([down_df_neg, raw_df_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corresponding-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 284807\n",
      "    Positive: 492 (0.17% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(down_df['Class'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aggressive-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = down_df.copy()\n",
    "\n",
    "# You don't want the `Time` column.\n",
    "cleaned_df.pop('Time')\n",
    "\n",
    "# The `Amount` column covers a huge range. Convert to log-space.\n",
    "eps = 0.001 # 0 => 0.1Â¢\n",
    "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atmospheric-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twelve-moral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (182276,)\n",
      "Validation labels shape: (45569,)\n",
      "Test labels shape: (56962,)\n",
      "Training features shape: (182276, 29)\n",
      "Validation features shape: (45569, 29)\n",
      "Test features shape: (56962, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "encouraging-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_features,\n",
    "                        train_labels.astype(np.float64).reshape(-1, 1))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=config[\"batch_size\"],\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = DataSet(test_features,\n",
    "                       test_labels.astype(np.float64).reshape(-1, 1))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=config[\"batch_size\"],\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alone-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "\n",
    "class FirstNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FirstNet, self).__init__()        \n",
    "        self.L1 = nn.Linear(train_features.shape[-1],\n",
    "                            hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SecondNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SecondNet, self).__init__()        \n",
    "        self.L2 = nn.Linear(hidden_dim,\n",
    "                            1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "def torch_auc(label, pred):\n",
    "    return roc_auc_score(label.detach().numpy(),\n",
    "                         pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wrong-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.00067803, metric 0.8212399688135726\n",
      "epoch 2, loss 3.1159e-05, metric 0.9683496092080551\n",
      "epoch 3, loss 2.2184e-05, metric 0.982390608629873\n"
     ]
    }
   ],
   "source": [
    "model_1 = FirstNet()\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "model_2 = SecondNet()\n",
    "model_2 = model_2.to(device)\n",
    "\n",
    "model_1.double()\n",
    "model_2.double()\n",
    "\n",
    "opt_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "opt_2 = optim.Adam(model_2.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "client = Client(model_1, opt_1)\n",
    "server = Server(model_2, opt_2, criterion)\n",
    "\n",
    "sn = SplitNN(client, server, device=device)\n",
    "sn.fit(train_loader, 3, metric=torch_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surface-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999728385632264"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_leak_auc(sn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "executive-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server_with_max_norm(Server):\n",
    "    def __init__(self, server_model,\n",
    "                        server_optimizer,\n",
    "                        criterion):\n",
    "                super().__init__(server_model,\n",
    "                                server_optimizer,\n",
    "                                criterion)\n",
    "\n",
    "    def _fit_server(self, intermidiate_to_server, labels):\n",
    "        outputs = self.server_model(intermidiate_to_server)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        grad_to_client = intermidiate_to_server.grad.clone()\n",
    "        grad_to_client = max_norm(grad_to_client)\n",
    "        return outputs, loss, grad_to_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "attended-cameroon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.001561, metric 0.35758412146527374\n",
      "epoch 2, loss 0.00048577, metric 0.52705867511411\n",
      "epoch 3, loss 0.00031461, metric 0.5283707178953191\n",
      "epoch 4, loss 0.00022605, metric 0.5468446732904245\n",
      "epoch 5, loss 0.00018179, metric 0.5861497869670282\n",
      "epoch 6, loss 0.00015149, metric 0.6391923753977673\n",
      "epoch 7, loss 0.00012853, metric 0.7088472370278383\n",
      "epoch 8, loss 0.00010685, metric 0.7812909825556263\n",
      "epoch 9, loss 9.0646e-05, metric 0.8148555429784137\n",
      "epoch 10, loss 7.9543e-05, metric 0.8392497128168402\n"
     ]
    }
   ],
   "source": [
    "model_1 = FirstNet()\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "model_2 = SecondNet()\n",
    "model_2 = model_2.to(device)\n",
    "\n",
    "model_1.double()\n",
    "model_2.double()\n",
    "\n",
    "opt_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "opt_2 = optim.Adam(model_2.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "client = Client(model_1, opt_1)\n",
    "server = Server_with_max_norm(model_2, opt_2, criterion)\n",
    "\n",
    "sn = SplitNN(client, server, device=device)\n",
    "sn.fit(train_loader, 10, metric=torch_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grand-lighting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024231222205127072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_leak_auc(sn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-treaty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
