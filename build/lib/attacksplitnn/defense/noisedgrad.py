import torch


def max_norm(grad):
    """server-side heuristic approach to prevent label leakage attacks
       https://arxiv.org/abs/2102.08504

    Args:
        grad (torch.Tensor): the gradient of L with respect to the
                             input of the function h

                             ---
                                L : the loss function
                                f : the client side model
                                h : the server side model
                                the whole model can be expressed as h â—¦ f


    Returns:
        pertubated_gard (torch.Tensor): noised gradient which is
                                        supposed to be sent to the client

    Examples:
        # you have to create custom Server class
        class Server_with_max_norm(Server):
            def __init__(self, server_model,
                        server_optimizer,
                        criterion):
                super().__init__(server_model,
                                server_optimizer,
                                criterion)

            def _fit_server(self, intermidiate_to_server, labels):
                outputs = self.server_model(intermidiate_to_server)
                loss = self.criterion(outputs, labels)
                loss.backward()

                grad_to_client = intermidiate_to_server.grad.clone()
                grad_to_client = max_norm(grad_to_client)
                return outputs, loss, grad_to_client
    """

    g_norm = grad.pow(2).sum(dim=list(range(1, len(grad.shape)))).sqrt()
    # maximum gradient norm among the mini-batch
    g_max = g_norm[torch.argmax(g_norm)]
    # the standard deviation to be determined
    sigma = torch.sqrt(g_max / g_norm - 1)
    # gausiaan noise
    perturbation = torch.normal(torch.zeros_like(sigma), sigma)
    # expand dimension
    perturbation = perturbation.expand(list(grad.shape)[::-1]).T
    # perturbed gradient
    pertubated_gard = grad + perturbation

    return pertubated_gard
